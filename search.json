[
  {
    "objectID": "papers/2025-10-08-paper-template.html",
    "href": "papers/2025-10-08-paper-template.html",
    "title": "Self-Concordant Barriers Revisited",
    "section": "",
    "text": "Tip\n\n\n\nTL;DR 以自洽函数为桥梁，统一了内点法的复杂度与几何直觉。"
  },
  {
    "objectID": "papers/2025-10-08-paper-template.html#key-ideas",
    "href": "papers/2025-10-08-paper-template.html#key-ideas",
    "title": "Self-Concordant Barriers Revisited",
    "section": "Key Ideas",
    "text": "Key Ideas\n\nBarrier 的自洽性定义与局部二次近似…\nNewton decrement 与路径跟随…"
  },
  {
    "objectID": "papers/2025-10-08-paper-template.html#why-it-matters",
    "href": "papers/2025-10-08-paper-template.html#why-it-matters",
    "title": "Self-Concordant Barriers Revisited",
    "section": "Why it matters",
    "text": "Why it matters\n\n将凸优化的复杂度理论从“算法技巧”上升到“几何结构”…"
  },
  {
    "objectID": "papers/2025-10-08-paper-template.html#my-notes",
    "href": "papers/2025-10-08-paper-template.html#my-notes",
    "title": "Self-Concordant Barriers Revisited",
    "section": "My notes",
    "text": "My notes\n\n直观图示…\n延伸阅读：…"
  },
  {
    "objectID": "papers/2025-10-08-paper-template.html#bibtex",
    "href": "papers/2025-10-08-paper-template.html#bibtex",
    "title": "Self-Concordant Barriers Revisited",
    "section": "BibTeX",
    "text": "BibTeX\n```bibtex @article{nesterov1994interior, … }"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "PhD student / Researcher in Shanghai\nInterests: Probability, Machine Learning, Diffusion Models\nI write about ideas-in-progress — learning in public."
  },
  {
    "objectID": "about.html#about-me",
    "href": "about.html#about-me",
    "title": "About",
    "section": "",
    "text": "PhD student / Researcher in Shanghai\nInterests: Probability, Machine Learning, Diffusion Models\nI write about ideas-in-progress — learning in public."
  },
  {
    "objectID": "about.html#contact",
    "href": "about.html#contact",
    "title": "About",
    "section": "Contact",
    "text": "Contact\n\nGitHub: https://github.com/MIStatlE"
  },
  {
    "objectID": "guides/diffusion/notes/vae.html",
    "href": "guides/diffusion/notes/vae.html",
    "title": "VAE 基础推导",
    "section": "",
    "text": "我们希望估计某个分布 p(x)，用参数化模型 p_\\theta(x) 来近似，并通过极大似然估计优化参数：\n\n\\max_\\theta \\ \\mathbb{E}_{x\\sim p^*}[\\log p_\\theta(x)].\n\n但在高维空间上直接建模 p_\\theta(x) 通常非常困难，因此我们引入潜变量 z，将复杂分布分解为条件形式：\n\np_\\theta(x)=\\int p_\\theta(x|z)p(z)\\,dz,\n\n其中 p_\\theta(x|z) 称为 decoder（生成器），p(z) 是先验（通常取标准正态）。\n\n\n\n\n真实的后验 p_\\theta(z|x) 无法直接计算，于是定义可计算的近似分布：\n\nq_\\phi(z|x) \\approx p_\\theta(z|x),\n\n称为 encoder（编码器）。\n两者通常使用神经网络参数化：\n\nq_\\phi(z|x)=\\mathcal N(z|\\mu_\\phi(x),\\mathrm{diag}(\\sigma_\\phi^2(x))), \\quad\np_\\theta(x|z)=\\mathcal N(x|f_\\theta(z),\\sigma_{\\text{dec}}^2 I).\n\n\n\n\n\n直接优化 \\log p_\\theta(x) 不可行，因为积分项难计算：\n\np_\\theta(x)=\\int p_\\theta(x,z)\\,dz.\n\n于是我们引入 q_\\phi(z|x) 并重写：\n\n\\log p_\\theta(x)\n= \\log\\int q_\\phi(z|x)\\frac{p_\\theta(x,z)}{q_\\phi(z|x)}\\,dz\n= \\log \\mathbb{E}_{q_\\phi}\\!\\left[\\frac{p_\\theta(x,z)}{q_\\phi(z|x)}\\right].\n\n应用 Jensen 不等式（\\log \\mathbb{E}[\\cdot] \\ge \\mathbb{E}[\\log\\cdot]）得到：\n\n\\log p_\\theta(x)\n\\ge \\mathbb{E}_{q_\\phi}\\!\\left[\\log\\frac{p_\\theta(x,z)}{q_\\phi(z|x)}\\right]\n=: \\mathcal L(\\theta,\\phi;x),\n\n这就是著名的 Evidence Lower Bound (ELBO)。\n\n\n\n\n展开 p_\\theta(x,z)=p_\\theta(x|z)p(z)，有：\n\n\\mathcal L(\\theta,\\phi;x)\n= \\mathbb{E}_{q_\\phi(z|x)}[\\log p_\\theta(x|z)]\n- \\mathrm{KL}(q_\\phi(z|x)\\|p(z)).\n\n\n重建项：衡量生成器 p_\\theta(x|z) 对输入 x 的复现能力；\n正则项：约束编码器 q_\\phi(z|x) 贴近先验 p(z)，防止潜变量退化。\n\n等价关系：\n\n\\log p_\\theta(x)\n= \\mathcal L(\\theta,\\phi;x)\n+ \\mathrm{KL}(q_\\phi(z|x)\\|p_\\theta(z|x)),\n\n因此 ELBO 始终是 \\log p_\\theta(x) 的下界。\n\n推荐阅读：\n📖 arXiv:2406.08929 —— 一份以直觉为主的 Diffusion 入门材料。\n先建立整体框架，再看推导细节，会更高效。\n#生成模型 #VAE #Diffusion #变分推断"
  },
  {
    "objectID": "guides/diffusion/notes/vae.html#从极大似然出发",
    "href": "guides/diffusion/notes/vae.html#从极大似然出发",
    "title": "VAE 基础推导",
    "section": "",
    "text": "我们希望估计某个分布 p(x)，用参数化模型 p_\\theta(x) 来近似，并通过极大似然估计优化参数：\n\n\\max_\\theta \\ \\mathbb{E}_{x\\sim p^*}[\\log p_\\theta(x)].\n\n但在高维空间上直接建模 p_\\theta(x) 通常非常困难，因此我们引入潜变量 z，将复杂分布分解为条件形式：\n\np_\\theta(x)=\\int p_\\theta(x|z)p(z)\\,dz,\n\n其中 p_\\theta(x|z) 称为 decoder（生成器），p(z) 是先验（通常取标准正态）。"
  },
  {
    "objectID": "guides/diffusion/notes/vae.html#引入可计算的近似分布",
    "href": "guides/diffusion/notes/vae.html#引入可计算的近似分布",
    "title": "VAE 基础推导",
    "section": "",
    "text": "真实的后验 p_\\theta(z|x) 无法直接计算，于是定义可计算的近似分布：\n\nq_\\phi(z|x) \\approx p_\\theta(z|x),\n\n称为 encoder（编码器）。\n两者通常使用神经网络参数化：\n\nq_\\phi(z|x)=\\mathcal N(z|\\mu_\\phi(x),\\mathrm{diag}(\\sigma_\\phi^2(x))), \\quad\np_\\theta(x|z)=\\mathcal N(x|f_\\theta(z),\\sigma_{\\text{dec}}^2 I)."
  },
  {
    "objectID": "guides/diffusion/notes/vae.html#从最大似然到-elbo",
    "href": "guides/diffusion/notes/vae.html#从最大似然到-elbo",
    "title": "VAE 基础推导",
    "section": "",
    "text": "直接优化 \\log p_\\theta(x) 不可行，因为积分项难计算：\n\np_\\theta(x)=\\int p_\\theta(x,z)\\,dz.\n\n于是我们引入 q_\\phi(z|x) 并重写：\n\n\\log p_\\theta(x)\n= \\log\\int q_\\phi(z|x)\\frac{p_\\theta(x,z)}{q_\\phi(z|x)}\\,dz\n= \\log \\mathbb{E}_{q_\\phi}\\!\\left[\\frac{p_\\theta(x,z)}{q_\\phi(z|x)}\\right].\n\n应用 Jensen 不等式（\\log \\mathbb{E}[\\cdot] \\ge \\mathbb{E}[\\log\\cdot]）得到：\n\n\\log p_\\theta(x)\n\\ge \\mathbb{E}_{q_\\phi}\\!\\left[\\log\\frac{p_\\theta(x,z)}{q_\\phi(z|x)}\\right]\n=: \\mathcal L(\\theta,\\phi;x),\n\n这就是著名的 Evidence Lower Bound (ELBO)。"
  },
  {
    "objectID": "guides/diffusion/notes/vae.html#elbo-的结构与意义",
    "href": "guides/diffusion/notes/vae.html#elbo-的结构与意义",
    "title": "VAE 基础推导",
    "section": "",
    "text": "展开 p_\\theta(x,z)=p_\\theta(x|z)p(z)，有：\n\n\\mathcal L(\\theta,\\phi;x)\n= \\mathbb{E}_{q_\\phi(z|x)}[\\log p_\\theta(x|z)]\n- \\mathrm{KL}(q_\\phi(z|x)\\|p(z)).\n\n\n重建项：衡量生成器 p_\\theta(x|z) 对输入 x 的复现能力；\n正则项：约束编码器 q_\\phi(z|x) 贴近先验 p(z)，防止潜变量退化。\n\n等价关系：\n\n\\log p_\\theta(x)\n= \\mathcal L(\\theta,\\phi;x)\n+ \\mathrm{KL}(q_\\phi(z|x)\\|p_\\theta(z|x)),\n\n因此 ELBO 始终是 \\log p_\\theta(x) 的下界。\n\n推荐阅读：\n📖 arXiv:2406.08929 —— 一份以直觉为主的 Diffusion 入门材料。\n先建立整体框架，再看推导细节，会更高效。\n#生成模型 #VAE #Diffusion #变分推断"
  },
  {
    "objectID": "guides/index.html",
    "href": "guides/index.html",
    "title": "Guides Overview",
    "section": "",
    "text": "Guides Overview\nStart with Probability & Stats or Optimization.",
    "crumbs": [
      "Overview"
    ]
  },
  {
    "objectID": "tools/index.html",
    "href": "tools/index.html",
    "title": "Tools & Workflows",
    "section": "",
    "text": "可复用的研究/工程工具与工作流，强调 可操作 与 效率。\n\n\n\n\n\n\n\n    \n      \n      \n    \n\n\n\n\n\n\n\n\nQuarto 最佳实践：从 0 到“高信息密度”站点\n\n\n\n\n\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/index.html",
    "href": "posts/index.html",
    "title": "Posts",
    "section": "",
    "text": "Welcome to my posts.\n\n\n\n\n\n\n\n\n\nStarting Over: Building MIStatlE Lab\n\n\n\nmeta\n\nsetup\n\n\n\nA simple Quarto starter with math support, post listings, and GitHub Pages auto-deploy.\n\n\n\n\n\nOct 7, 2025\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "community/index.html",
    "href": "community/index.html",
    "title": "Community",
    "section": "",
    "text": "Community\nEvents, announcements, and resources."
  },
  {
    "objectID": "reads/index.html",
    "href": "reads/index.html",
    "title": "Good Reads",
    "section": "",
    "text": "高信息密度外部资源：长文、书单、课程、视频与博客。\n\n\n\n\n\n\n\n    \n      \n      \n    \n\n\n\n\nNo matching items"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Welcome",
    "section": "",
    "text": "Hello, I’m MIStatlE 👋\nThis is my minimal Quarto website. Math works out of the box:\n\nInline math: \\int_0^1 x^2\\,dx = 1/3\nDisplay math:\n\n\n\\mathbb{P}(|S_n - n\\mu| \\ge t) \\le 2\\exp\\!\\left(-\\frac{t^2}{2\\sigma^2 n}\\right).\n\nUse the Posts section for articles and notes. Edit _quarto.yml to customize the navbar and theme."
  },
  {
    "objectID": "search.html",
    "href": "search.html",
    "title": "FRAIMEL",
    "section": "",
    "text": "Tip\n\n\n\nUse the navbar search (browser) or your site search engine."
  },
  {
    "objectID": "search.html#title-search",
    "href": "search.html#title-search",
    "title": "FRAIMEL",
    "section": "",
    "text": "Tip\n\n\n\nUse the navbar search (browser) or your site search engine."
  },
  {
    "objectID": "posts/2025-10-07-welcome.html",
    "href": "posts/2025-10-07-welcome.html",
    "title": "Starting Over: Building MIStatlE Lab",
    "section": "",
    "text": "This is a starter post. You can write math like e^{i\\pi}+1=0 and code blocks:\ndef add(a, b): return a + b\nprint(add(2, 3))\nTo publish, just push to main — GitHub Actions will render and deploy to gh-pages."
  },
  {
    "objectID": "tools/quarto-setup.html",
    "href": "tools/quarto-setup.html",
    "title": "Quarto 最佳实践：从 0 到“高信息密度”站点",
    "section": "",
    "text": "Markdown+数学+列表页+RSS，一体化…\n适合“利他型”学习空间：低摩擦、高输出。"
  },
  {
    "objectID": "tools/quarto-setup.html#why-quarto",
    "href": "tools/quarto-setup.html#why-quarto",
    "title": "Quarto 最佳实践：从 0 到“高信息密度”站点",
    "section": "",
    "text": "Markdown+数学+列表页+RSS，一体化…\n适合“利他型”学习空间：低摩擦、高输出。"
  },
  {
    "objectID": "tools/quarto-setup.html#setup",
    "href": "tools/quarto-setup.html#setup",
    "title": "Quarto 最佳实践：从 0 到“高信息密度”站点",
    "section": "Setup",
    "text": "Setup\n```bash quarto create-project MIStatlE-Lab quarto add quarto-ext/fontawesome"
  },
  {
    "objectID": "guides/diffusion/index.html",
    "href": "guides/diffusion/index.html",
    "title": "Diffusion Models",
    "section": "",
    "text": "学习目标\n从零到一理解扩散模型：动机 → 高斯扩散 → 反向 SDE/ODE → DDPM/DDIM → Flow Matching → 理论与实践。"
  },
  {
    "objectID": "guides/diffusion/index.html#扩散模型要解决的问题",
    "href": "guides/diffusion/index.html#扩散模型要解决的问题",
    "title": "Diffusion Models",
    "section": "扩散模型要解决的问题",
    "text": "扩散模型要解决的问题\n生成模型希望学习未知分布 p^*(x)，从而生成近似样本。\n直接从噪声“一步”生成复杂数据往往困难，而扩散模型的关键在于：\n\n前向扩散（Forward Diffusion）：逐步加噪，使数据分布趋近高斯；\n反向过程（Reverse Diffusion）：学习去噪映射，把噪声还原为数据；\n每一步都只需建模相邻分布 p(x_{t-\\Delta t}\\mid x_t)，学习更稳定。\n\n\n核心等价关系：\n\\text{Denoising} \\;\\Leftrightarrow\\; \\text{Learning } \\nabla_x \\log p_t(x)\n学习去噪即学习“得分函数”，方向即密度上升最快的方向。"
  },
  {
    "objectID": "guides/diffusion/index.html#模型概览",
    "href": "guides/diffusion/index.html#模型概览",
    "title": "Diffusion Models",
    "section": "模型概览",
    "text": "模型概览\n\n\n\n\n\n\n\n\n模型\n核心特征\n适合理解的方向\n\n\n\n\nDDPM (Ho et al., 2020)\n随机反演，采样多样性强\n适合学习随机微分方程与噪声调度思想\n\n\nDDIM (Song et al., 2020)\n确定性采样，速度快\n适合工程与推理效率研究\n\n\nFlow Matching (Lipman et al., 2023)\n统一连续流框架\n适合理解 ODE/SDE 统一与几何流"
  },
  {
    "objectID": "guides/diffusion/index.html#推荐网课与讲座",
    "href": "guides/diffusion/index.html#推荐网课与讲座",
    "title": "Diffusion Models",
    "section": "🎓 推荐网课与讲座",
    "text": "🎓 推荐网课与讲座\n\n\n\n课程\n来源\n定位与特点\n适合人群\n\n\n\n\nMIT 6.S980 — Diffusion Models\nMIT\n最系统的扩散入门课程；讲清从加噪→去噪→采样的完整流程，覆盖 DDPM、SDE、Flow Matching\n希望“系统掌握原理+数学背景”的研究生\n\n\nCS236 — Deep Generative Models\nStanford\n将扩散模型放在生成模型的整体框架中讲解（与VAE、GAN对比）\n想理解扩散在整个生成建模中的位置\n\n\nSTAT 157 — Deep Unsupervised Learning\nBerkeley\n从“概率建模 + 实验”的角度介绍 score-based 方法，重视动机和实践\n想边学边做、快速上手的同学\n\n\nDiffusion Seminar Series\nDeepMind × UCL\n汇集各大实验室研究者讲解前沿思想（Consistency、Flow Matching 等）\n已有基础，想了解学界前沿动向的人"
  },
  {
    "objectID": "guides/diffusion/index.html#推荐资料与书籍",
    "href": "guides/diffusion/index.html#推荐资料与书籍",
    "title": "Diffusion Models",
    "section": "推荐资料与书籍",
    "text": "推荐资料与书籍\n\n入门推荐：Step-by-Step Diffusion（arXiv:2406.08929）\n\n原文：https://arxiv.org/pdf/2406.08929\n\n这篇教程以最小数学依赖讲解扩散模型的核心直觉与采样流程，强调“加噪→去噪”的构造思路，帮助快速形成整体认知（DDPM、DDIM、Flow Matching 的联系与差异），在Appendix里整理了更深入的内容。\n谁适合读？ - 想先抓“为什么这样做”的直觉，而非从繁琐推导的数学理论开始；\n\n\n下方自动汇总所有 Diffusion 相关笔记（notes/*.qmd）\n在 guides/diffusion/notes/ 目录中添加新 .qmd 文件即可自动展示。"
  },
  {
    "objectID": "guides/diffusion/notes/ddpm.html",
    "href": "guides/diffusion/notes/ddpm.html",
    "title": "DDPM 基础推导",
    "section": "",
    "text": "简述：x_{t+\\Delta t}=x_t+\\eta_t,\\ \\eta_t\\sim\\mathcal N(0,\\sigma_q^2\\Delta t)。小步噪声下， p(x_{t-\\Delta t}\\mid x_t)\\approx \\mathcal N(\\mu_t(x_t),\\sigma_q^2\\Delta t)， 回归目标 \\arg\\min_f \\mathbb E\\|f(x_t)-x_{t-\\Delta t}\\|^2。"
  },
  {
    "objectID": "papers/index.html",
    "href": "papers/index.html",
    "title": "Paper Picks",
    "section": "",
    "text": "高信号论文精选：关注 ML Theory / RL / Optimization / Generative Models。\n\n\n\n\n\n\n\n   \n    \n    \n      Order By\n      Default\n      \n        Title\n      \n    \n  \n    \n      \n      \n    \n\n\n\n\n\n\nTitle\n\n\n\nauthors\n\n\n\nvenue\n\n\n\nyear\n\n\n\ntags\n\n\n\n\n\n\n\n\nSelf-Concordant Barriers Revisited\n\n\nNesterov, Nemirovski\n\n\nMath. Programming\n\n\n1994\n\n\noptimization, self-concordant, interior-point\n\n\n\n\n\n\nNo matching items"
  }
]