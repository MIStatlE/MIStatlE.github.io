---
title: "Policy Gradient 其实没那么神秘"
---

# 我们要最大化的是什么

我们定义回报
$$
J(\theta) = \mathbb{E}_\pi \left[ \sum_{t=0}^\infty \gamma^t r_t \right].
$$

这不是玄学，这是优化目标。

## 梯度长什么样
经典策略梯度定理给出：
$$
\nabla_\theta J(\theta)
= \mathbb{E}_\pi \big[
   \nabla_\theta \log \pi_\theta(a|s) \, R
\big].
$$

## 直觉
“谁带来高回报，就让它以后更容易再次发生。”
